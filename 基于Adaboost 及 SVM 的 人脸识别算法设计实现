

import os
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from matplotlib import rcParams
import cv2

from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

# è®¾ç½®ä¸­æ–‡å­—ä½“
rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun', 'KaiTi', 'FangSong', 'Arial Unicode MS']
rcParams['axes.unicode_minus'] = False

# ============================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šäººè„¸æ£€æµ‹ (Haar-like + Adaboost)
# ============================================

class HaarFeature:
    """Haar-likeç‰¹å¾æå–å™¨"""
    
    def __init__(self, feature_type, position, width, height):
        """
        feature_type: ç‰¹å¾ç±»å‹ ('two_horizontal', 'two_vertical', 'three_horizontal', 'four')
        position: (x, y) ç‰¹å¾ä½ç½®
        width, height: ç‰¹å¾çª—å£å¤§å°
        """
        self.feature_type = feature_type
        self.position = position
        self.width = width
        self.height = height
    
    def compute(self, integral_image):
        """ä½¿ç”¨ç§¯åˆ†å›¾è®¡ç®—Haarç‰¹å¾å€¼"""
        x, y = self.position
        w, h = self.width, self.height
        
        if self.feature_type == 'two_horizontal':
            # å·¦ç™½å³é»‘
            left = self._sum_region(integral_image, x, y, w//2, h)
            right = self._sum_region(integral_image, x + w//2, y, w//2, h)
            return right - left
            
        elif self.feature_type == 'two_vertical':
            # ä¸Šç™½ä¸‹é»‘
            top = self._sum_region(integral_image, x, y, w, h//2)
            bottom = self._sum_region(integral_image, x, y + h//2, w, h//2)
            return bottom - top
            
        elif self.feature_type == 'three_horizontal':
            # å·¦ç™½ä¸­é»‘å³ç™½
            left = self._sum_region(integral_image, x, y, w//3, h)
            middle = self._sum_region(integral_image, x + w//3, y, w//3, h)
            right = self._sum_region(integral_image, x + 2*w//3, y, w//3, h)
            return middle - (left + right)
            
        elif self.feature_type == 'four':
            # å››è±¡é™
            tl = self._sum_region(integral_image, x, y, w//2, h//2)
            tr = self._sum_region(integral_image, x + w//2, y, w//2, h//2)
            bl = self._sum_region(integral_image, x, y + h//2, w//2, h//2)
            br = self._sum_region(integral_image, x + w//2, y + h//2, w//2, h//2)
            return (br + tl) - (tr + bl)
    
    def _sum_region(self, integral_image, x, y, width, height):
        """ä½¿ç”¨ç§¯åˆ†å›¾å¿«é€Ÿè®¡ç®—çŸ©å½¢åŒºåŸŸå’Œ"""
        x, y = int(x), int(y)
        width, height = int(width), int(height)
        
        # é˜²æ­¢è¶Šç•Œ
        h, w = integral_image.shape
        x2 = min(x + width, w - 1)
        y2 = min(y + height, h - 1)
        x = min(x, w - 1)
        y = min(y, h - 1)
        
        # ç§¯åˆ†å›¾è®¡ç®—ï¼šD - B - C + A
        total = integral_image[y2, x2]
        if x > 0:
            total -= integral_image[y2, x - 1]
        if y > 0:
            total -= integral_image[y - 1, x2]
        if x > 0 and y > 0:
            total += integral_image[y - 1, x - 1]
        
        return total


def compute_integral_image(image):
    """è®¡ç®—ç§¯åˆ†å›¾"""
    if len(image.shape) == 3:
        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    return np.cumsum(np.cumsum(image, axis=0), axis=1).astype(np.float64)


def generate_haar_features(image_width, image_height, feature_count):
    """ç”ŸæˆæŒ‡å®šæ•°é‡çš„Haar-likeç‰¹å¾"""
    features = []
    feature_types = ['two_horizontal', 'two_vertical', 'three_horizontal', 'four']
    
    np.random.seed(42)
    
    for _ in range(feature_count):
        feature_type = np.random.choice(feature_types)
        
        # éšæœºç”Ÿæˆç‰¹å¾çª—å£å¤§å°å’Œä½ç½®
        w = np.random.randint(10, min(image_width // 2, 50))
        h = np.random.randint(10, min(image_height // 2, 50))
        x = np.random.randint(0, max(1, image_width - w))
        y = np.random.randint(0, max(1, image_height - h))
        
        features.append(HaarFeature(feature_type, (x, y), w, h))
    
    return features


def extract_features_from_image(image, haar_features):
    """ä»å›¾åƒä¸­æå–Haarç‰¹å¾"""
    integral_img = compute_integral_image(image)
    feature_vector = []
    
    for haar_feature in haar_features:
        feature_value = haar_feature.compute(integral_img)
        feature_vector.append(feature_value)
    
    return np.array(feature_vector)


# ============================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šæ•°æ®åŠ è½½
# ============================================

def load_orl_dataset(dataset_path='att_faces'):
    """
    åŠ è½½ ORL äººè„¸æ•°æ®åº“
    è¿”å›ï¼šè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å›¾åƒåŠæ ‡ç­¾
    """
    X_train_images, y_train = [], []
    X_test_images, y_test = [], []
    
    # éå†æ¯ä¸ªäººçš„æ–‡ä»¶å¤¹ (s1, s2, ..., s40)
    for i in range(1, 41):
        person_folder = os.path.join(dataset_path, f's{i}')
        images = sorted([os.path.join(person_folder, f) for f in os.listdir(person_folder)],
                        key=lambda x: int(os.path.basename(x).split('.')[0]))
        
        for idx, img_path in enumerate(images):
            try:
                img = Image.open(img_path)
                img_array = np.array(img)
                label = i
                
                if idx < 6:  # å‰6å¼ ä½œä¸ºè®­ç»ƒé›†
                    X_train_images.append(img_array)
                    y_train.append(label)
                else:  # å4å¼ ä½œä¸ºæµ‹è¯•é›†
                    X_test_images.append(img_array)
                    y_test.append(label)
            except Exception as e:
                print(f"Error reading {img_path}: {e}")
    
    return X_train_images, np.array(y_train), X_test_images, np.array(y_test)


# ============================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®éªŒä¸»ç¨‹åº
# ============================================

if __name__ == '__main__':
    print("="*80)
    print("å®éªŒäºŒï¼šåŸºäºAdabooståŠSVMçš„äººè„¸è¯†åˆ«ç®—æ³•è®¾è®¡å®ç°")
    print("="*80)
    
    # åŠ è½½æ•°æ®
    print("\næ­£åœ¨åŠ è½½ORLäººè„¸æ•°æ®é›†...")
    X_train_images, y_train, X_test_images, y_test = load_orl_dataset()
    print(f"è®­ç»ƒé›†: {len(X_train_images)} å¼ å›¾åƒ")
    print(f"æµ‹è¯•é›†: {len(X_test_images)} å¼ å›¾åƒ")
    print(f"å›¾åƒå°ºå¯¸: {X_train_images[0].shape}")
    
    # ============================================
    # å®éªŒ1ï¼šAdaboostç®—æ³• - ç‰¹å¾æ•°å¯¹äººè„¸æ£€æµ‹çš„å½±å“
    # ============================================
    print("\n" + "="*80)
    print("å®éªŒ1ï¼šAdaboostäººè„¸æ£€æµ‹ - ä¸åŒHaarç‰¹å¾æ•°é‡çš„å½±å“")
    print("="*80)
    
    feature_counts = [20, 50, 100, 200]
    adaboost_detection_accuracies = []
    
    img_height, img_width = X_train_images[0].shape
    
    for n_features in feature_counts:
        print(f"\næ­£åœ¨æµ‹è¯• {n_features} ä¸ªHaarç‰¹å¾...")
        
        # 1. ç”ŸæˆHaarç‰¹å¾
        haar_features = generate_haar_features(img_width, img_height, n_features)
        
        # 2. æå–è®­ç»ƒé›†ç‰¹å¾
        print(f"  æå–è®­ç»ƒé›†ç‰¹å¾...")
        X_train_haar = []
        for img in X_train_images:
            features = extract_features_from_image(img, haar_features)
            X_train_haar.append(features)
        X_train_haar = np.array(X_train_haar)
        
        # 3. æå–æµ‹è¯•é›†ç‰¹å¾
        print(f"  æå–æµ‹è¯•é›†ç‰¹å¾...")
        X_test_haar = []
        for img in X_test_images:
            features = extract_features_from_image(img, haar_features)
            X_test_haar.append(features)
        X_test_haar = np.array(X_test_haar)
        
        # 4. ä½¿ç”¨Adaboostè¿›è¡Œåˆ†ç±»ï¼ˆäººè„¸è¯†åˆ«ï¼‰
        print(f"  è®­ç»ƒAdabooståˆ†ç±»å™¨...")
        ada_classifier = AdaBoostClassifier(
            estimator=DecisionTreeClassifier(max_depth=3),
            n_estimators=100,
            learning_rate=0.8,
            random_state=42
        )
        ada_classifier.fit(X_train_haar, y_train)
        
        # 5. é¢„æµ‹ä¸è¯„ä¼°
        y_pred = ada_classifier.predict(X_test_haar)
        accuracy = accuracy_score(y_test, y_pred)
        adaboost_detection_accuracies.append(accuracy)
        print(f"  âœ“ Haarç‰¹å¾æ•°: {n_features}, Adaboostå‡†ç¡®ç‡: {accuracy*100:.2f}%")
    
    # ç»˜åˆ¶ç»“æœå›¾ - ç°ä»£æ¸å˜è®¾è®¡
    fig, ax = plt.subplots(figsize=(12, 7), facecolor='white')
    
    # æ¸å˜è‰²ç³»
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']
    bars = ax.bar(range(len(feature_counts)), adaboost_detection_accuracies,
                   color=colors, alpha=0.85, edgecolor='white', linewidth=2.5)
    
    # æ·»åŠ èƒŒæ™¯è‰²
    ax.set_facecolor('#F8F9FA')
    
    # æ ‡é¢˜å’Œæ ‡ç­¾
    ax.set_title('å®éªŒ1ï¼šAdaboostäººè„¸æ£€æµ‹ - Haarç‰¹å¾æ•°é‡å½±å“åˆ†æ', 
                fontsize=16, fontweight='bold', pad=20, color='#2C3E50')
    ax.set_xlabel('Haarç‰¹å¾æ•°é‡', fontsize=13, fontweight='bold', color='#34495E')
    ax.set_ylabel('è¯†åˆ«å‡†ç¡®ç‡', fontsize=13, fontweight='bold', color='#34495E')
    ax.set_xticks(range(len(feature_counts)))
    ax.set_xticklabels(feature_counts, fontsize=11)
    ax.set_ylim(0, max(adaboost_detection_accuracies)*1.15)
    
    # æŸ”å’Œç½‘æ ¼
    ax.grid(axis='y', alpha=0.2, linestyle='-', linewidth=1, color='#BDC3C7')
    ax.set_axisbelow(True)
    
    # æ•°å€¼æ ‡æ³¨å¸¦èƒŒæ™¯
    for idx, (bar, acc) in enumerate(zip(bars, adaboost_detection_accuracies)):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                f'{acc*100:.2f}%',
                ha='center', va='bottom', fontsize=12, fontweight='bold',
                color='#2C3E50',
                bbox=dict(boxstyle='round,pad=0.5', facecolor='white', 
                         edgecolor=colors[idx], alpha=0.8, linewidth=2))
    
    # ç¾åŒ–è¾¹æ¡†
    for spine in ax.spines.values():
        spine.set_edgecolor('#BDC3C7')
        spine.set_linewidth(1.5)
    
    plt.tight_layout()
    plt.savefig('å®éªŒ1_Adaboost_Haarç‰¹å¾æ•°å¯¹æ¯”.png', dpi=300, bbox_inches='tight', facecolor='white')
    print("\nâœ“ å›¾è¡¨å·²ä¿å­˜: å®éªŒ1_Adaboost_Haarç‰¹å¾æ•°å¯¹æ¯”.png")
    plt.show()
    plt.close()
    
    # ============================================
    # å®éªŒ2ï¼šPCAé™ç»´ + SVMäººè„¸è¯†åˆ«
    # ============================================
    print("\n" + "="*80)
    print("å®éªŒ2aï¼šPCAé™ç»´å¯¹SVMäººè„¸è¯†åˆ«çš„å½±å“")
    print("="*80)
    
    # å°†å›¾åƒè½¬æ¢ä¸ºå‘é‡
    X_train_flat = np.array([img.flatten() for img in X_train_images])
    X_test_flat = np.array([img.flatten() for img in X_test_images])
    
    n_components_list = [20, 50, 100, 200]
    svm_pca_accuracies = []
    
    for n_components in n_components_list:
        print(f"\næ­£åœ¨æµ‹è¯• PCAé™ç»´åˆ° {n_components} ç»´...")
        
        # 1. PCAé™ç»´
        pca = PCA(n_components=n_components, svd_solver='randomized', whiten=True)
        X_train_pca = pca.fit_transform(X_train_flat)
        X_test_pca = pca.transform(X_test_flat)
        
        # 2. æ•°æ®è§„æ ¼åŒ–
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train_pca)
        X_test_scaled = scaler.transform(X_test_pca)
        
        # 3. SVMè®­ç»ƒï¼ˆä½¿ç”¨å¾„å‘åŸºå‡½æ•°ï¼‰
        svm_classifier = SVC(kernel='rbf', gamma='auto', random_state=42)
        svm_classifier.fit(X_train_scaled, y_train)
        
        # 4. é¢„æµ‹ä¸è¯„ä¼°
        y_pred = svm_classifier.predict(X_test_scaled)
        accuracy = accuracy_score(y_test, y_pred)
        svm_pca_accuracies.append(accuracy)
        print(f"  âœ“ PCAç»´åº¦: {n_components}, SVMå‡†ç¡®ç‡: {accuracy*100:.2f}%")
    
    # ç»˜åˆ¶ç»“æœå›¾ - ç°ä»£è®¾è®¡
    fig, ax = plt.subplots(figsize=(12, 7), facecolor='white')
    
    # ä¸“ä¸šé…è‰²
    colors = ['#667EEA', '#764BA2', '#F093FB', '#4FACFE']
    bars = ax.bar(range(len(n_components_list)), svm_pca_accuracies,
                   color=colors, alpha=0.85, edgecolor='white', linewidth=2.5)
    
    ax.set_facecolor('#F8F9FA')
    
    ax.set_title('å®éªŒ2aï¼šPCAé™ç»´å¯¹SVMäººè„¸è¯†åˆ«çš„å½±å“', 
                fontsize=16, fontweight='bold', pad=20, color='#2C3E50')
    ax.set_xlabel('PCAé™ç»´ç»´åº¦', fontsize=13, fontweight='bold', color='#34495E')
    ax.set_ylabel('è¯†åˆ«å‡†ç¡®ç‡', fontsize=13, fontweight='bold', color='#34495E')
    ax.set_xticks(range(len(n_components_list)))
    ax.set_xticklabels(n_components_list, fontsize=11)
    ax.set_ylim(0, max(svm_pca_accuracies)*1.15)
    
    ax.grid(axis='y', alpha=0.2, linestyle='-', linewidth=1, color='#BDC3C7')
    ax.set_axisbelow(True)
    
    # æ ‡æ³¨æœ€ä½³ç»“æœ
    best_idx = np.argmax(svm_pca_accuracies)
    for idx, (bar, acc) in enumerate(zip(bars, svm_pca_accuracies)):
        height = bar.get_height()
        if idx == best_idx:
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{acc*100:.2f}%\nâ˜… æœ€ä¼˜',
                    ha='center', va='bottom', fontsize=12, fontweight='bold',
                    color='#E74C3C',
                    bbox=dict(boxstyle='round,pad=0.6', facecolor='#FFD700', 
                             edgecolor='#E74C3C', alpha=0.9, linewidth=2.5))
        else:
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{acc*100:.2f}%',
                    ha='center', va='bottom', fontsize=12, fontweight='bold',
                    color='#2C3E50',
                    bbox=dict(boxstyle='round,pad=0.5', facecolor='white', 
                             edgecolor=colors[idx], alpha=0.8, linewidth=2))
    
    for spine in ax.spines.values():
        spine.set_edgecolor('#BDC3C7')
        spine.set_linewidth(1.5)
    
    plt.tight_layout()
    plt.savefig('å®éªŒ2a_PCAé™ç»´å¯¹æ¯”.png', dpi=300, bbox_inches='tight', facecolor='white')
    print("\nâœ“ å›¾è¡¨å·²ä¿å­˜: å®éªŒ2a_PCAé™ç»´å¯¹æ¯”.png")
    plt.show()
    plt.close()
    
    # ============================================
    # å®éªŒ2bï¼šSVMä¸åŒæ ¸å‡½æ•°å¯¹æ¯”
    # ============================================
    print("\n" + "="*80)
    print("å®éªŒ2bï¼šSVMä¸åŒæ ¸å‡½æ•°å¯¹äººè„¸è¯†åˆ«çš„å½±å“")
    print("="*80)
    
    # ğŸ”¥ ä¿®æ­£ï¼šä½¿ç”¨å®éªŒ2aå¾—å‡ºçš„æœ€ä¼˜PCAç»´åº¦
    optimal_n_components = n_components_list[np.argmax(svm_pca_accuracies)]
    print(f"æ ¹æ®å®éªŒ2aç»“æœï¼Œé€‰æ‹©æœ€ä¼˜ PCA ç»´åº¦: {optimal_n_components} (å‡†ç¡®ç‡: {max(svm_pca_accuracies)*100:.2f}%)")
    
    # PCAé™ç»´
    pca = PCA(n_components=optimal_n_components, svd_solver='randomized', whiten=True)
    X_train_pca = pca.fit_transform(X_train_flat)
    X_test_pca = pca.transform(X_test_flat)
    
    # æ•°æ®è§„æ ¼åŒ–
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train_pca)
    X_test_scaled = scaler.transform(X_test_pca)
    
    kernels = ['linear', 'rbf', 'poly', 'sigmoid']
    kernel_names = ['çº¿æ€§æ ¸', 'å¾„å‘åŸºæ ¸(RBF)', 'å¤šé¡¹å¼æ ¸', 'Sigmoidæ ¸']
    svm_kernel_accuracies = {}
    
    for kernel, kernel_name in zip(kernels, kernel_names):
        print(f"\næ­£åœ¨æµ‹è¯• SVMæ ¸å‡½æ•°: {kernel_name}...")
        svm_classifier = SVC(kernel=kernel, gamma='auto', random_state=42)
        svm_classifier.fit(X_train_scaled, y_train)
        
        y_pred = svm_classifier.predict(X_test_scaled)
        accuracy = accuracy_score(y_test, y_pred)
        svm_kernel_accuracies[kernel_name] = accuracy
        print(f"  âœ“ æ ¸å‡½æ•°: {kernel_name}, å‡†ç¡®ç‡: {accuracy*100:.2f}%")
    
    # ç»˜åˆ¶ç»“æœå›¾ - ç°ä»£è®¾è®¡
    fig, ax = plt.subplots(figsize=(12, 7), facecolor='white')
    
    # ä¸“ä¸šæ¸å˜é…è‰²
    colors = ['#FA709A', '#FEE140', '#30CFD0', '#A8EDEA']
    bars = ax.bar(range(len(svm_kernel_accuracies)), svm_kernel_accuracies.values(),
                   color=colors, alpha=0.85, edgecolor='white', linewidth=2.5)
    
    ax.set_facecolor('#F8F9FA')
    
    ax.set_title(f'å®éªŒ2bï¼šSVMæ ¸å‡½æ•°å¯¹æ¯” (PCAç»´åº¦={optimal_n_components})',
              fontsize=16, fontweight='bold', pad=20, color='#2C3E50')
    ax.set_xlabel('æ ¸å‡½æ•°ç±»å‹', fontsize=13, fontweight='bold', color='#34495E')
    ax.set_ylabel('è¯†åˆ«å‡†ç¡®ç‡', fontsize=13, fontweight='bold', color='#34495E')
    ax.set_xticks(range(len(svm_kernel_accuracies)))
    ax.set_xticklabels(svm_kernel_accuracies.keys(), rotation=0, fontsize=11)
    ax.set_ylim(0, max(svm_kernel_accuracies.values())*1.15)
    
    ax.grid(axis='y', alpha=0.2, linestyle='-', linewidth=1, color='#BDC3C7')
    ax.set_axisbelow(True)
    
    # æ‰¾å‡ºæœ€ä½³æ ¸å‡½æ•°
    best_kernel = max(svm_kernel_accuracies, key=svm_kernel_accuracies.get)
    for idx, (bar, (kernel_name, acc)) in enumerate(zip(bars, svm_kernel_accuracies.items())):
        height = bar.get_height()
        if kernel_name == best_kernel:
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{acc*100:.2f}%\nâ˜… æœ€ä¼˜',
                    ha='center', va='bottom', fontsize=12, fontweight='bold',
                    color='#E74C3C',
                    bbox=dict(boxstyle='round,pad=0.6', facecolor='#FFD700', 
                             edgecolor='#E74C3C', alpha=0.9, linewidth=2.5))
        else:
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{acc*100:.2f}%',
                    ha='center', va='bottom', fontsize=12, fontweight='bold',
                    color='#2C3E50',
                    bbox=dict(boxstyle='round,pad=0.5', facecolor='white', 
                             edgecolor=colors[idx], alpha=0.8, linewidth=2))
    
    for spine in ax.spines.values():
        spine.set_edgecolor('#BDC3C7')
        spine.set_linewidth(1.5)
    
    plt.tight_layout()
    plt.savefig('å®éªŒ2b_SVMæ ¸å‡½æ•°å¯¹æ¯”.png', dpi=300, bbox_inches='tight', facecolor='white')
    print("\nâœ“ å›¾è¡¨å·²ä¿å­˜: å®éªŒ2b_SVMæ ¸å‡½æ•°å¯¹æ¯”.png")
    plt.show()
    plt.close()
    
    # ============================================
    # å®éªŒ3ï¼šäº¤å‰éªŒè¯ - å¯¹æ¯”æ‰€æœ‰æ ¸å‡½æ•°
    # ============================================
    print("\n" + "="*80)
    print("å®éªŒ3ï¼šä½¿ç”¨äº¤å‰éªŒè¯å¯¹æ¯”ä¸åŒSVMæ ¸å‡½æ•°")
    print("="*80)
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®ç”¨äºäº¤å‰éªŒè¯
    X_all = np.concatenate((X_train_flat, X_test_flat), axis=0)
    y_all = np.concatenate((y_train, y_test), axis=0)
    print(f"å®Œæ•´æ•°æ®é›†å½¢çŠ¶: {X_all.shape}")
    print(f"ä½¿ç”¨æœ€ä¼˜ PCA ç»´åº¦: {optimal_n_components}")
    
    # ğŸ”¥ å¯¹æ¯ä¸ªæ ¸å‡½æ•°éƒ½è¿›è¡Œ5æŠ˜äº¤å‰éªŒè¯
    kernels = ['linear', 'rbf', 'poly', 'sigmoid']
    kernel_names = ['çº¿æ€§æ ¸', 'å¾„å‘åŸºæ ¸(RBF)', 'å¤šé¡¹å¼æ ¸', 'Sigmoidæ ¸']
    cv_results = {}  # å­˜å‚¨æ¯ä¸ªæ ¸å‡½æ•°çš„äº¤å‰éªŒè¯ç»“æœ
    
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    
    print("\næ­£åœ¨å¯¹æ‰€æœ‰æ ¸å‡½æ•°æ‰§è¡Œ5æŠ˜äº¤å‰éªŒè¯...")
    for kernel, kernel_name in zip(kernels, kernel_names):
        print(f"\n  æ­£åœ¨éªŒè¯ {kernel_name}...")
        
        # ä¸ºæ¯ä¸ªæ ¸å‡½æ•°åˆ›å»ºPipeline
        pipeline = Pipeline([
            ('pca', PCA(n_components=optimal_n_components, svd_solver='randomized', whiten=True)),
            ('scaler', StandardScaler()),
            ('svm', SVC(kernel=kernel, gamma='auto', random_state=42))
        ])
        
        # æ‰§è¡Œäº¤å‰éªŒè¯
        cv_scores = cross_val_score(pipeline, X_all, y_all, cv=kf, scoring='accuracy')
        cv_results[kernel_name] = cv_scores
        
        print(f"    å„æŠ˜å‡†ç¡®ç‡: {[f'{s*100:.2f}%' for s in cv_scores]}")
        print(f"    âœ“ å¹³å‡å‡†ç¡®ç‡: {np.mean(cv_scores)*100:.2f}% Â± {np.std(cv_scores)*100:.2f}%")
    
    # æ‰¾å‡ºæœ€ä¼˜æ ¸å‡½æ•°
    mean_accuracies = {k: np.mean(v) for k, v in cv_results.items()}
    best_kernel_cv = max(mean_accuracies, key=mean_accuracies.get)
    best_accuracy_cv = mean_accuracies[best_kernel_cv]
    
    print(f"\n{'='*60}")
    print(f"äº¤å‰éªŒè¯ç»“è®º:")
    print(f"  â˜… æœ€ä¼˜æ ¸å‡½æ•°: {best_kernel_cv}")
    print(f"  â˜… æœ€é«˜å¹³å‡å‡†ç¡®ç‡: {best_accuracy_cv*100:.2f}%")
    print(f"{'='*60}")
    
    # ç»˜åˆ¶æŠ˜çº¿å›¾å¯¹æ¯” - ç°ä»£è®¾è®¡
    fig, ax = plt.subplots(figsize=(14, 8), facecolor='white')
    
    # ç°ä»£æ¸å˜é…è‰²
    colors = ['#667EEA', '#FA709A', '#2DDA93', '#FFA07A']
    markers = ['o', 's', 'D', '^']
    linestyles = ['-', '-', '-', '-']  # ç»Ÿä¸€çº¿å‹ï¼Œç”¨é¢œè‰²åŒºåˆ†
    folds = list(range(1, 6))
    
    # è®¾ç½®èƒŒæ™¯
    ax.set_facecolor('#F8F9FA')
    
    # ä¸ºäº†é¿å…é‡å ï¼Œå¯¹xåæ ‡è¿›è¡Œå¾®è°ƒ
    offsets = [-0.1, -0.035, 0.035, 0.1]
    
    # ç»˜åˆ¶æ¯ä¸ªæ ¸å‡½æ•°çš„æŠ˜çº¿
    for idx, ((kernel_name, cv_scores), color, marker, linestyle, offset) in enumerate(
            zip(cv_results.items(), colors, markers, linestyles, offsets)):
        mean_acc = np.mean(cv_scores)
        
        # åº”ç”¨xåç§»ï¼Œé¿å…æŠ˜çº¿é‡å 
        x_positions = [f + offset for f in folds]
        
        # åˆ¤æ–­æ˜¯å¦æ˜¯æœ€ä¼˜æ ¸å‡½æ•°
        is_best = (kernel_name == best_kernel_cv)
        linewidth = 3.5 if is_best else 2.5
        markersize = 12 if is_best else 10
        alpha = 1.0 if is_best else 0.8
        
        # å¦‚æœæ˜¯æœ€ä¼˜æ ¸å‡½æ•°ï¼Œæ·»åŠ å‘å…‰æ•ˆæœ
        if is_best:
            ax.plot(x_positions, cv_scores*100, marker=marker, color=color, 
                    linewidth=linewidth+4, linestyle=linestyle, markersize=markersize+2, 
                    alpha=0.2, markeredgewidth=0, zorder=1)
        
        ax.plot(x_positions, cv_scores*100, marker=marker, color=color, 
                linewidth=linewidth, linestyle=linestyle, markersize=markersize, 
                label=f'{kernel_name} (å‡å€¼: {mean_acc*100:.2f}%)', alpha=alpha,
                markeredgecolor='white', markeredgewidth=2, zorder=3)
        
        # åªåœ¨æœ€ä¼˜å’Œæ¬¡ä¼˜æ ¸å‡½æ•°ä¸Šæ ‡æ³¨æ•°å€¼
        if mean_acc > 0.88:
            for i, score in enumerate(cv_scores):
                va = 'bottom' if idx % 2 == 0 else 'top'
                y_offset = 1.2 if idx % 2 == 0 else -1.2
                ax.text(x_positions[i], score*100 + y_offset, f'{score*100:.1f}', 
                        ha='center', va=va, fontsize=9, color=color, 
                        fontweight='bold', alpha=0.9)
    
    # æ ‡æ³¨æœ€ä¼˜æ ¸å‡½æ•°çš„å¹³å‡çº¿
    best_scores = cv_results[best_kernel_cv]
    best_mean = np.mean(best_scores)
    ax.axhline(y=best_mean*100, color='#E74C3C', linestyle='--', linewidth=2.5, 
               alpha=0.5, label=f'æœ€ä¼˜å¹³å‡çº¿: {best_mean*100:.2f}%', zorder=2)
    
    ax.set_title(f'å®éªŒ3ï¼šäº¤å‰éªŒè¯ - SVMæ ¸å‡½æ•°æ€§èƒ½å¯¹æ¯” (PCA={optimal_n_components}ç»´)', 
              fontsize=16, fontweight='bold', pad=20, color='#2C3E50')
    ax.set_xlabel('æŠ˜æ•°', fontsize=13, fontweight='bold', color='#34495E')
    ax.set_ylabel('å‡†ç¡®ç‡ (%)', fontsize=13, fontweight='bold', color='#34495E')
    ax.set_xticks(folds)
    ax.set_xticklabels([f'ç¬¬{i}æŠ˜' for i in folds], fontsize=11)
    ax.tick_params(axis='both', labelsize=11)
    ax.set_ylim(25, 102)
    
    # æŸ”å’Œç½‘æ ¼
    ax.grid(True, alpha=0.2, linestyle='-', linewidth=1, color='#BDC3C7', zorder=0)
    ax.set_axisbelow(True)
    
    # å›¾ä¾‹æ”¾åœ¨å³ä¾§
    ax.legend(loc='center left', bbox_to_anchor=(1.02, 0.5), fontsize=11, 
              framealpha=0.95, edgecolor='#BDC3C7', fancybox=True, 
              shadow=False, frameon=True, facecolor='white')
    
    # æœ€ä¼˜æ ‡è®° - é‡‘è‰²å¾½ç« æ ·å¼
    ax.text(0.02, 0.50, 
            f'â˜… æœ€ä¼˜æ ¸å‡½æ•°\n{best_kernel_cv}\nå¹³å‡: {best_mean*100:.2f}%\næ ‡å‡†å·®: Â±{np.std(best_scores)*100:.2f}%', 
            transform=ax.transAxes, fontsize=12, verticalalignment='center',
            horizontalalignment='left',
            bbox=dict(boxstyle='round,pad=0.8', facecolor='#FFD700', alpha=0.9, 
                     edgecolor='#E74C3C', linewidth=3),
            fontweight='bold', color='#2C3E50')
    
    # ç¾åŒ–è¾¹æ¡†
    for spine in ax.spines.values():
        spine.set_edgecolor('#BDC3C7')
        spine.set_linewidth(1.5)
    
    plt.tight_layout()
    plt.savefig('å®éªŒ3_äº¤å‰éªŒè¯ç»“æœ.png', dpi=300, bbox_inches='tight', facecolor='white')
    print("\nâœ“ å›¾è¡¨å·²ä¿å­˜: å®éªŒ3_äº¤å‰éªŒè¯ç»“æœ.png")
    plt.show()
    plt.close()
    
    # ============================================
    # å®éªŒæ€»ç»“
    # ============================================
    print("\n" + "="*80)
    print("å®éªŒæ€»ç»“")
    print("="*80)
    
    # æœ€ä¼˜Adaboostç‰¹å¾æ•°
    best_haar_idx = np.argmax(adaboost_detection_accuracies)
    print(f"\n1. Adaboostäººè„¸æ£€æµ‹:")
    print(f"   æœ€ä¼˜Haarç‰¹å¾æ•°: {feature_counts[best_haar_idx]}")
    print(f"   æœ€é«˜å‡†ç¡®ç‡: {adaboost_detection_accuracies[best_haar_idx]*100:.2f}%")
    
    # æœ€ä¼˜PCAç»´åº¦
    best_pca_idx = np.argmax(svm_pca_accuracies)
    print(f"\n2. PCAé™ç»´ + SVMè¯†åˆ«:")
    print(f"   æœ€ä¼˜PCAç»´åº¦: {n_components_list[best_pca_idx]}")
    print(f"   æœ€é«˜å‡†ç¡®ç‡: {svm_pca_accuracies[best_pca_idx]*100:.2f}%")
    
    # æœ€ä¼˜SVMæ ¸å‡½æ•°
    best_kernel = max(svm_kernel_accuracies, key=svm_kernel_accuracies.get)
    print(f"\n3. SVMæ ¸å‡½æ•°å¯¹æ¯”:")
    print(f"   æœ€ä¼˜æ ¸å‡½æ•°: {best_kernel}")
    print(f"   æœ€é«˜å‡†ç¡®ç‡: {svm_kernel_accuracies[best_kernel]*100:.2f}%")
    
    # äº¤å‰éªŒè¯ç»“æœ
    print(f"\n4. äº¤å‰éªŒè¯è¯„ä¼°:")
    print(f"   æœ€ä¼˜æ ¸å‡½æ•°: {best_kernel_cv}")
    print(f"   å¹³å‡å‡†ç¡®ç‡: {best_accuracy_cv*100:.2f}%")
    print(f"   æ‰€æœ‰æ ¸å‡½æ•°å¯¹æ¯”:")
    for kernel_name, scores in cv_results.items():
        print(f"     - {kernel_name}: {np.mean(scores)*100:.2f}% Â± {np.std(scores)*100:.2f}%")
    
    # æ–¹æ³•å¯¹æ¯”
    print(f"\n5. æ–¹æ³•å¯¹æ¯”:")
    print(f"   Adaboost (Haarç‰¹å¾): {max(adaboost_detection_accuracies)*100:.2f}%")
    print(f"   SVM (PCAç‰¹å¾): {max(svm_pca_accuracies)*100:.2f}%")
    print(f"   ç»“è®º: SVMæ–¹æ³•åœ¨æœ¬å®éªŒä¸­è¡¨ç°æ›´ä¼˜")
    
    print("\n" + "="*80)
    print("æ‰€æœ‰å®éªŒå®Œæˆï¼å›¾è¡¨å·²ä¿å­˜åˆ°å½“å‰ç›®å½•ã€‚")
    print("å…±ç”Ÿæˆ4å¼ å›¾è¡¨ï¼š")
    print("  1. å®éªŒ1_Adaboost_Haarç‰¹å¾æ•°å¯¹æ¯”.png")
    print("  2. å®éªŒ2a_PCAé™ç»´å¯¹æ¯”.png")
    print("  3. å®éªŒ2b_SVMæ ¸å‡½æ•°å¯¹æ¯”.png")
    print("  4. å®éªŒ3_äº¤å‰éªŒè¯ç»“æœ.png")
    print("="*80)
    
    # ============================================
    # æ‰©å±•å®éªŒï¼šå››ä¸ªæ¨¡å‹å¯¹æ¯”ï¼ˆ5æŠ˜äº¤å‰éªŒè¯å‡†ç¡®ç‡ï¼‰
    # ============================================
    print("\n" + "="*80)
    print("æ‰©å±•å®éªŒï¼šå››ä¸ªæ¨¡å‹å¯¹æ¯”ï¼ˆ5æŠ˜äº¤å‰éªŒè¯å‡†ç¡®ç‡ï¼‰")
    print("="*80)
    
    # PSOä¼˜åŒ–ç®—æ³•å®ç°
    class PSO:
        """ç²’å­ç¾¤ä¼˜åŒ–ç®—æ³•"""
        def __init__(self, n_particles=20, n_iterations=30, bounds=None, w=0.7, c1=1.5, c2=1.5):
            """
            n_particles: ç²’å­æ•°é‡
            n_iterations: è¿­ä»£æ¬¡æ•°
            bounds: å‚æ•°è¾¹ç•Œ [(min, max), ...]
            w: æƒ¯æ€§æƒé‡
            c1, c2: å­¦ä¹ å› å­
            """
            self.n_particles = n_particles
            self.n_iterations = n_iterations
            self.bounds = bounds
            self.w = w
            self.c1 = c1
            self.c2 = c2
            self.global_best_position = None
            self.global_best_score = -np.inf
        
        def optimize(self, objective_func):
            """æ‰§è¡ŒPSOä¼˜åŒ–"""
            # åˆå§‹åŒ–ç²’å­ä½ç½®å’Œé€Ÿåº¦
            particles = np.random.uniform(
                low=[b[0] for b in self.bounds],
                high=[b[1] for b in self.bounds],
                size=(self.n_particles, len(self.bounds))
            )
            velocities = np.random.uniform(
                low=-1, high=1,
                size=(self.n_particles, len(self.bounds))
            )
            
            # åˆå§‹åŒ–ä¸ªä½“æœ€ä¼˜
            personal_best_positions = particles.copy()
            personal_best_scores = np.array([objective_func(p) for p in particles])
            
            # åˆå§‹åŒ–å…¨å±€æœ€ä¼˜
            best_idx = np.argmax(personal_best_scores)
            self.global_best_position = personal_best_positions[best_idx].copy()
            self.global_best_score = personal_best_scores[best_idx]
            
            # è¿­ä»£ä¼˜åŒ–
            for iteration in range(self.n_iterations):
                for i in range(self.n_particles):
                    # æ›´æ–°é€Ÿåº¦
                    r1, r2 = np.random.rand(2)
                    velocities[i] = (self.w * velocities[i] +
                                    self.c1 * r1 * (personal_best_positions[i] - particles[i]) +
                                    self.c2 * r2 * (self.global_best_position - particles[i]))
                    
                    # æ›´æ–°ä½ç½®
                    particles[i] += velocities[i]
                    
                    # è¾¹ç•Œå¤„ç†
                    for j in range(len(self.bounds)):
                        if particles[i, j] < self.bounds[j][0]:
                            particles[i, j] = self.bounds[j][0]
                        elif particles[i, j] > self.bounds[j][1]:
                            particles[i, j] = self.bounds[j][1]
                    
                    # è¯„ä¼°æ–°ä½ç½®
                    score = objective_func(particles[i])
                    
                    # æ›´æ–°ä¸ªä½“æœ€ä¼˜
                    if score > personal_best_scores[i]:
                        personal_best_scores[i] = score
                        personal_best_positions[i] = particles[i].copy()
                        
                        # æ›´æ–°å…¨å±€æœ€ä¼˜
                        if score > self.global_best_score:
                            self.global_best_score = score
                            self.global_best_position = particles[i].copy()
            
            return self.global_best_position, self.global_best_score
    
    # å‡†å¤‡æ•°æ®ï¼ˆä½¿ç”¨æœ€ä¼˜PCAç»´åº¦ï¼‰
    print(f"\nä½¿ç”¨æœ€ä¼˜PCAç»´åº¦: {optimal_n_components}")
    pca = PCA(n_components=optimal_n_components, svd_solver='randomized', whiten=True)
    X_all_pca = pca.fit_transform(X_all)
    scaler = StandardScaler()
    X_all_scaled = scaler.fit_transform(X_all_pca)
    
    # 5æŠ˜äº¤å‰éªŒè¯
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    
    # æ¨¡å‹1ï¼šæœ€ä½³SVCæ¨¡å‹ï¼ˆä»å®éªŒ3ä¸­é€‰æ‹©æœ€ä¼˜æ ¸å‡½æ•°ï¼‰
    best_kernel_name = best_kernel_cv
    # å°†ä¸­æ–‡æ ¸å‡½æ•°åæ˜ å°„å›sklearnçš„æ ¸å‡½æ•°å
    kernel_map = {
        'çº¿æ€§æ ¸': 'linear',
        'å¾„å‘åŸºæ ¸(RBF)': 'rbf',
        'å¤šé¡¹å¼æ ¸': 'poly',
        'Sigmoidæ ¸': 'sigmoid'
    }
    best_kernel = kernel_map[best_kernel_name]
    
    print(f"\næ¨¡å‹1ï¼šæœ€ä½³SVCæ¨¡å‹ï¼ˆ{best_kernel_name}ï¼‰")
    print("  æ­£åœ¨è¿›è¡Œ5æŠ˜äº¤å‰éªŒè¯...")
    
    def evaluate_model_accuracy(model, X, y, cv):
        """è¯„ä¼°æ¨¡å‹çš„å‡†ç¡®ç‡ï¼ˆ5æŠ˜äº¤å‰éªŒè¯ï¼‰"""
        acc_scores = []
        for train_idx, val_idx in cv.split(X, y):
            X_train_fold, X_val_fold = X[train_idx], X[val_idx]
            y_train_fold, y_val_fold = y[train_idx], y[val_idx]
            
            model.fit(X_train_fold, y_train_fold)
            y_pred = model.predict(X_val_fold)
            acc = accuracy_score(y_val_fold, y_pred)
            acc_scores.append(acc)
        return np.array(acc_scores)
    
    # æ¨¡å‹1ï¼šæœ€ä½³SVC
    best_svc = SVC(kernel=best_kernel, gamma='auto', random_state=42)
    svc_acc_scores = evaluate_model_accuracy(best_svc, X_all_scaled, y_all, kf)
    svc_mean_acc = np.mean(svc_acc_scores)
    print(f"  âœ“ å¹³å‡å‡†ç¡®ç‡: {svc_mean_acc*100:.4f}% Â± {np.std(svc_acc_scores)*100:.4f}%")
    
    # æ¨¡å‹2ï¼šRandom Forest
    print(f"\næ¨¡å‹2ï¼šRandom Forest")
    print("  æ­£åœ¨è¿›è¡Œ5æŠ˜äº¤å‰éªŒè¯...")
    rf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)
    rf_acc_scores = evaluate_model_accuracy(rf, X_all_scaled, y_all, kf)
    rf_mean_acc = np.mean(rf_acc_scores)
    print(f"  âœ“ å¹³å‡å‡†ç¡®ç‡: {rf_mean_acc*100:.4f}% Â± {np.std(rf_acc_scores)*100:.4f}%")
    
    # æ¨¡å‹3ï¼šKNN
    print(f"\næ¨¡å‹3ï¼šKNN")
    print("  æ­£åœ¨è¿›è¡Œ5æŠ˜äº¤å‰éªŒè¯...")
    knn = KNeighborsClassifier(n_neighbors=5)
    knn_acc_scores = evaluate_model_accuracy(knn, X_all_scaled, y_all, kf)
    knn_mean_acc = np.mean(knn_acc_scores)
    print(f"  âœ“ å¹³å‡å‡†ç¡®ç‡: {knn_mean_acc*100:.4f}% Â± {np.std(knn_acc_scores)*100:.4f}%")
    
    # æ¨¡å‹4ï¼šPSOä¼˜åŒ–çš„SVC
    print(f"\næ¨¡å‹4ï¼šPSOä¼˜åŒ–çš„SVCï¼ˆ{best_kernel_name}ï¼‰")
    print("  æ­£åœ¨è¿›è¡ŒPSOä¼˜åŒ–...")
    
    # å®šä¹‰ç›®æ ‡å‡½æ•°ï¼ˆä½¿ç”¨5æŠ˜äº¤å‰éªŒè¯çš„å‡†ç¡®ç‡ï¼Œæ›´é€‚åˆåˆ†ç±»é—®é¢˜ï¼‰
    def pso_objective_svc(params):
        """PSOä¼˜åŒ–çš„ç›®æ ‡å‡½æ•°ï¼ˆä½¿ç”¨å‡†ç¡®ç‡ï¼‰"""
        C = params[0]
        # é™åˆ¶å‚æ•°èŒƒå›´ï¼ˆä¸pso_boundsä¿æŒä¸€è‡´ï¼‰
        if C < 0.01 or C > 1000:
            return -np.inf
        
        # æ ¹æ®æ ¸å‡½æ•°ç±»å‹é€‰æ‹©å‚æ•°
        if best_kernel == 'linear':
            # çº¿æ€§æ ¸åªéœ€è¦Cå‚æ•°
            svc_temp = SVC(kernel=best_kernel, C=C, random_state=42)
        else:
            # å…¶ä»–æ ¸å‡½æ•°éœ€è¦Cå’Œgamma
            gamma = params[1] if len(params) > 1 else 'auto'
            if isinstance(gamma, (int, float)) and (gamma < 0.0001 or gamma > 10):
                return -np.inf
            svc_temp = SVC(kernel=best_kernel, C=C, gamma=gamma, random_state=42)
        
        # ä½¿ç”¨5æŠ˜äº¤å‰éªŒè¯è¯„ä¼°ï¼ˆä¸æœ€ç»ˆè¯„ä¼°ä¿æŒä¸€è‡´ï¼‰
        # ä½¿ç”¨å‡†ç¡®ç‡ä½œä¸ºä¼˜åŒ–ç›®æ ‡ï¼ˆæ›´é€‚åˆåˆ†ç±»é—®é¢˜ï¼‰
        kf_temp = KFold(n_splits=5, shuffle=True, random_state=42)
        scores = []
        for train_idx, val_idx in kf_temp.split(X_all_scaled, y_all):
            X_train_fold, X_val_fold = X_all_scaled[train_idx], X_all_scaled[val_idx]
            y_train_fold, y_val_fold = y_all[train_idx], y_all[val_idx]
            svc_temp.fit(X_train_fold, y_train_fold)
            y_pred = svc_temp.predict(X_val_fold)
            acc = accuracy_score(y_val_fold, y_pred)  # ä½¿ç”¨å‡†ç¡®ç‡è€Œä¸æ˜¯R2
            scores.append(acc)
        return np.mean(scores)
    
    # å…ˆæ£€æŸ¥é»˜è®¤å‚æ•°çš„æ€§èƒ½
    print("  æ£€æŸ¥é»˜è®¤å‚æ•°æ€§èƒ½...")
    default_svc = SVC(kernel=best_kernel, gamma='auto', random_state=42)
    default_acc_temp = evaluate_model_accuracy(default_svc, X_all_scaled, y_all, kf)
    default_acc_mean = np.mean(default_acc_temp)
    print(f"  é»˜è®¤å‚æ•°(C=1.0)å¹³å‡å‡†ç¡®ç‡: {default_acc_mean*100:.4f}%")
    
    # PSOä¼˜åŒ–SVCå‚æ•°ï¼ˆæ ¹æ®æ ¸å‡½æ•°ç±»å‹é€‰æ‹©å‚æ•°ï¼‰
    if best_kernel == 'linear':
        # çº¿æ€§æ ¸åªä¼˜åŒ–Cï¼Œå¢åŠ æœç´¢èŒƒå›´
        pso_bounds = [(0.01, 1000)]  # æ‰©å¤§æœç´¢èŒƒå›´
        pso = PSO(n_particles=20, n_iterations=30, bounds=pso_bounds)  # å¢åŠ ç²’å­æ•°å’Œè¿­ä»£æ¬¡æ•°
        best_params, best_pso_score = pso.optimize(pso_objective_svc)
        best_C, best_gamma = best_params[0], 'auto'
        print(f"  âœ“ PSOä¼˜åŒ–ç»“æœ: C={best_C:.4f} (çº¿æ€§æ ¸ä¸éœ€è¦gamma)")
    else:
        # å…¶ä»–æ ¸å‡½æ•°ä¼˜åŒ–Cå’Œgamma
        pso_bounds = [(0.01, 1000), (0.0001, 10)]  # Cå’Œgammaçš„èŒƒå›´
        pso = PSO(n_particles=20, n_iterations=30, bounds=pso_bounds)  # å¢åŠ ç²’å­æ•°å’Œè¿­ä»£æ¬¡æ•°
        best_params, best_pso_score = pso.optimize(pso_objective_svc)
        best_C, best_gamma = best_params[0], best_params[1]
        print(f"  âœ“ PSOä¼˜åŒ–ç»“æœ: C={best_C:.4f}, gamma={best_gamma:.4f}")
    
    print(f"  âœ“ PSOä¼˜åŒ–ç›®æ ‡å€¼(å‡†ç¡®ç‡): {best_pso_score*100:.4f}%")  # æ˜¾ç¤º4ä½å°æ•°
    improvement = (best_pso_score - default_acc_mean) * 100
    print(f"  âœ“ ç›¸æ¯”é»˜è®¤å‚æ•°æ”¹è¿›: {improvement:+.4f}%")  # æ˜¾ç¤ºæ­£è´Ÿå·å’Œ4ä½å°æ•°
    print("  æ­£åœ¨è¿›è¡Œ5æŠ˜äº¤å‰éªŒè¯ï¼ˆæœ€ç»ˆè¯„ä¼°ï¼‰...")
    
    # ä½¿ç”¨PSOä¼˜åŒ–çš„å‚æ•°è¿›è¡Œ5æŠ˜äº¤å‰éªŒè¯
    if best_kernel == 'linear':
        pso_svc = SVC(kernel=best_kernel, C=best_C, random_state=42)
    else:
        pso_svc = SVC(kernel=best_kernel, C=best_C, gamma=best_gamma, random_state=42)
    pso_svc_acc_scores = evaluate_model_accuracy(pso_svc, X_all_scaled, y_all, kf)
    pso_svc_mean_acc = np.mean(pso_svc_acc_scores)
    print(f"  âœ“ å¹³å‡å‡†ç¡®ç‡: {pso_svc_mean_acc*100:.4f}% Â± {np.std(pso_svc_acc_scores)*100:.4f}%")
    
    # åˆ†æPSOä¼˜åŒ–æ•ˆæœ
    final_improvement = (pso_svc_mean_acc - default_acc_mean) * 100
    print(f"\n  ã€PSOä¼˜åŒ–åˆ†æã€‘")
    if abs(final_improvement) < 0.01:
        print(f"  âš  å‡†ç¡®ç‡æ”¹è¿›: {final_improvement:+.4f}% (å‡ ä¹æ— å˜åŒ–)")
        print(f"  è¯´æ˜: é»˜è®¤å‚æ•°C=1.0å·²ç»æ¥è¿‘æœ€ä¼˜ï¼ŒPSOæ‰¾åˆ°çš„C={best_C:.4f}æ•ˆæœç›¸ä¼¼")
        print(f"  åŸå› : çº¿æ€§æ ¸SVCåœ¨æ­¤æ•°æ®é›†ä¸Šå¯¹Cå‚æ•°ä¸æ•æ„Ÿï¼Œæˆ–å·²è¾¾åˆ°æ¨¡å‹æ€§èƒ½ä¸Šé™")
    elif final_improvement > 0:
        print(f"  âœ“ å‡†ç¡®ç‡æ”¹è¿›: {final_improvement:+.4f}% (æœ‰æå‡)")
        print(f"  PSOæˆåŠŸä¼˜åŒ–å‚æ•°ï¼Œä»C=1.0æå‡åˆ°C={best_C:.4f}")
    else:
        print(f"  âš  å‡†ç¡®ç‡æ”¹è¿›: {final_improvement:+.4f}% (ç•¥æœ‰ä¸‹é™)")
        print(f"  å¯èƒ½åŸå› : äº¤å‰éªŒè¯çš„éšæœºæ€§æˆ–è¿‡æ‹Ÿåˆ")
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "="*80)
    print("å››ä¸ªæ¨¡å‹å¯¹æ¯”ç»“æœï¼ˆ5æŠ˜äº¤å‰éªŒè¯å‡†ç¡®ç‡ï¼‰")
    print("="*80)
    
    results_acc = {
        f'æœ€ä½³SVC ({best_kernel_name})': svc_mean_acc,
        'Random Forest': rf_mean_acc,
        'KNN': knn_mean_acc,
        f'PSOä¼˜åŒ–SVC ({best_kernel_name})': pso_svc_mean_acc
    }
    
    # æŒ‰å‡†ç¡®ç‡æ’åº
    sorted_results_acc = sorted(results_acc.items(), key=lambda x: x[1], reverse=True)
    
    print("\nã€å‡†ç¡®ç‡æ’åã€‘")
    for rank, (model_name, mean_acc) in enumerate(sorted_results_acc, 1):
        marker = "â˜…" if rank == 1 else "  "
        print(f"{marker} {rank}. {model_name}: {mean_acc*100:.4f}%")
    
    print("\n" + "-"*80)
    print("ã€è¯´æ˜ã€‘")
    print("1. å‡†ç¡®ç‡æ˜¯åˆ†ç±»é—®é¢˜çš„æ ‡å‡†è¯„ä¼°æŒ‡æ ‡")
    print("2. PSOä¼˜åŒ–ä½¿ç”¨å‡†ç¡®ç‡ä½œä¸ºç›®æ ‡å‡½æ•°")
    print("3. å¦‚æœPSOæ”¹è¿›å¾ˆå°ï¼Œå¯èƒ½åŸå› ï¼š")
    print("   - é»˜è®¤å‚æ•°C=1.0å·²ç»æ¥è¿‘æœ€ä¼˜")
    print("   - æ¨¡å‹å·²è¾¾åˆ°æ€§èƒ½ä¸Šé™ï¼ˆæ•°æ®é›†é™åˆ¶ï¼‰")
    print("   - çº¿æ€§æ ¸å¯¹Cå‚æ•°ä¸æ•æ„Ÿ")
    print("4. ä½¿ç”¨4ä½å°æ•°ç²¾åº¦å¯ä»¥çœ‹åˆ°å¾®å°çš„å·®å¼‚")
    print("-"*80)
    
    # ç»˜åˆ¶å¯¹æ¯”å›¾ï¼ˆä½¿ç”¨å‡†ç¡®ç‡ï¼‰
    fig, ax = plt.subplots(figsize=(14, 8), facecolor='white')
    
    # å‡†å¤‡æ•°æ®ï¼ˆä½¿ç”¨å‡†ç¡®ç‡ï¼‰
    model_names = list(results_acc.keys())
    mean_accs = [x * 100 for x in results_acc.values()]  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
    std_accs = [
        np.std(svc_acc_scores) * 100,
        np.std(rf_acc_scores) * 100,
        np.std(knn_acc_scores) * 100,
        np.std(pso_svc_acc_scores) * 100
    ]
    
    # ä¸“ä¸šé…è‰²
    colors = ['#667EEA', '#FA709A', '#2DDA93', '#FFA07A']
    
    # ç»˜åˆ¶æŸ±çŠ¶å›¾
    bars = ax.bar(range(len(model_names)), mean_accs, 
                   color=colors, alpha=0.85, edgecolor='white', linewidth=2.5,
                   yerr=std_accs, capsize=8, error_kw={'elinewidth': 2, 'capthick': 2})
    
    ax.set_facecolor('#F8F9FA')
    
    ax.set_title('æ‰©å±•å®éªŒï¼šå››ä¸ªæ¨¡å‹å¯¹æ¯”ï¼ˆ5æŠ˜äº¤å‰éªŒè¯å¹³å‡å‡†ç¡®ç‡ï¼‰', 
                fontsize=16, fontweight='bold', pad=20, color='#2C3E50')
    ax.set_xlabel('æ¨¡å‹', fontsize=13, fontweight='bold', color='#34495E')
    ax.set_ylabel('å¹³å‡å‡†ç¡®ç‡ (%)', fontsize=13, fontweight='bold', color='#34495E')
    ax.set_xticks(range(len(model_names)))
    ax.set_xticklabels(model_names, rotation=15, ha='right', fontsize=11)
    
    # è®¾ç½®yè½´èŒƒå›´ï¼ˆé€‚åˆå‡†ç¡®ç‡ç™¾åˆ†æ¯”ï¼‰
    y_min = min(mean_accs) - max(std_accs) - 5
    y_max = max(mean_accs) + max(std_accs) + 5
    ax.set_ylim(max(y_min, 0), min(y_max, 100))
    
    ax.grid(axis='y', alpha=0.2, linestyle='-', linewidth=1, color='#BDC3C7')
    ax.set_axisbelow(True)
    
    # æ ‡æ³¨æ•°å€¼
    best_idx = np.argmax(mean_accs)
    for idx, (bar, mean_acc, std_acc) in enumerate(zip(bars, mean_accs, std_accs)):
        height = bar.get_height()
        if idx == best_idx:
            ax.text(bar.get_x() + bar.get_width()/2., height + std_acc + 0.5,
                    f'{mean_acc:.2f}%\nÂ±{std_acc:.2f}%\nâ˜… æœ€ä¼˜',
                    ha='center', va='bottom', fontsize=11, fontweight='bold',
                    color='#E74C3C',
                    bbox=dict(boxstyle='round,pad=0.6', facecolor='#FFD700', 
                             edgecolor='#E74C3C', alpha=0.9, linewidth=2.5))
        else:
            ax.text(bar.get_x() + bar.get_width()/2., height + std_acc + 0.5,
                    f'{mean_acc:.2f}%\nÂ±{std_acc:.2f}%',
                    ha='center', va='bottom', fontsize=11, fontweight='bold',
                    color='#2C3E50',
                    bbox=dict(boxstyle='round,pad=0.5', facecolor='white', 
                             edgecolor=colors[idx], alpha=0.8, linewidth=2))
    
    # ç¾åŒ–è¾¹æ¡†
    for spine in ax.spines.values():
        spine.set_edgecolor('#BDC3C7')
        spine.set_linewidth(1.5)
    
    plt.tight_layout()
    plt.savefig('æ‰©å±•å®éªŒ_å››ä¸ªæ¨¡å‹å‡†ç¡®ç‡å¯¹æ¯”.png', dpi=300, bbox_inches='tight', facecolor='white')
    print("\nâœ“ å›¾è¡¨å·²ä¿å­˜: æ‰©å±•å®éªŒ_å››ä¸ªæ¨¡å‹å‡†ç¡®ç‡å¯¹æ¯”.png")
    plt.show()
    plt.close()
    
    print("\n" + "="*80)
    print("æ‰©å±•å®éªŒå®Œæˆï¼")
    print("="*80)

